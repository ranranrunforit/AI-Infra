---
# ConfigMap for Prometheus configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: llm-platform
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    # Load alert rules
    rule_files:
      - '/etc/prometheus/rules/*.yml'
    
    scrape_configs:
      # Scrape the LLM API
      - job_name: 'llm-api'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - llm-platform
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

---
# ConfigMap for Prometheus Alert Rules (auto-loaded)
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: llm-platform
data:
  llm-alerts.yml: |
    groups:
      - name: llm_api_alerts
        interval: 30s
        rules:
          # High latency alert
          - alert: HighAPILatency
            expr: histogram_quantile(0.95, rate(llm_request_duration_seconds_bucket[5m])) > 10
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High API latency detected"
              description: "P95 latency is {{ $value }}s (threshold: 10s)"
          
          # High error rate alert
          - alert: HighErrorRate
            expr: rate(llm_requests_total{status=~"5.."}[5m]) / rate(llm_requests_total[5m]) > 0.05
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
          
          # Service down alert
          - alert: ServiceDown
            expr: up{job="llm-api"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "LLM API service is down"
              description: "The LLM API service has been down for more than 1 minute"
          
          # Low GPU utilization alert
          - alert: LowGPUUtilization
            expr: gpu_utilization_percent < 30
            for: 10m
            labels:
              severity: warning
            annotations:
              summary: "Low GPU utilization"
              description: "GPU utilization is {{ $value }}% (threshold: 30%)"
          
          # High GPU memory alert
          - alert: HighGPUMemory
            expr: (gpu_memory_used_mb / gpu_memory_total_mb) > 0.9
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High GPU memory usage"
              description: "GPU memory usage is {{ $value | humanizePercentage }} (threshold: 90%)"
          
          # High monthly cost projection
          - alert: HighMonthlyCost
            expr: rate(llm_cost_total[1h]) * 24 * 30 > 1000
            for: 1h
            labels:
              severity: warning
            annotations:
              summary: "High projected monthly cost"
              description: "Projected monthly cost is ${{ $value }} (threshold: $1000)"
          
          # Pod restarting frequently
          - alert: PodRestartingFrequently
            expr: rate(kube_pod_container_status_restarts_total{namespace="llm-platform"}[1h]) > 0
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Pod restarting frequently"
              description: "Pod {{ $labels.pod }} has restarted {{ $value }} times in the last hour"
          
          # Insufficient replicas
          - alert: InsufficientReplicas
            expr: kube_deployment_status_replicas_available{namespace="llm-platform",deployment="llm-api"} < 2
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Insufficient replicas running"
              description: "Only {{ $value }} replicas available (expected: 2+)"

---
# Prometheus Deployment with auto-loaded rules
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: llm-platform
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
        - name: prometheus
          image: prom/prometheus:v2.48.0
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.console.libraries=/usr/share/prometheus/console_libraries'
            - '--web.console.templates=/usr/share/prometheus/consoles'
            - '--web.enable-lifecycle'
          ports:
            - name: web
              containerPort: 9090
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: rules
              mountPath: /etc/prometheus/rules
            - name: storage
              mountPath: /prometheus
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: rules
          configMap:
            name: prometheus-rules
        - name: storage
          persistentVolumeClaim:
            claimName: prometheus-storage

---
# Prometheus Service
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: llm-platform
  labels:
    app: prometheus
spec:
  type: NodePort
  ports:
    - name: web
      port: 9090
      targetPort: 9090
      nodePort: 30090
  selector:
    app: prometheus

---
# PVC for Prometheus storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: llm-platform
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard

---
# ServiceAccount for Prometheus
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: llm-platform

---
# ClusterRole for Prometheus to discover pods
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]

---
# ClusterRoleBinding for Prometheus
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: llm-platform