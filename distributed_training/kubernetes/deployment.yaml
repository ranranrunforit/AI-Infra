---
# Fixed Kubernetes Deployment for Ray Distributed Training
# Optimized for single GPU (RTX 5070) with proper dashboard and logging

apiVersion: v1
kind: Namespace
metadata:
  name: ray-cluster
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ray-serviceaccount
  namespace: ray-cluster
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ray-config
  namespace: ray-cluster
data:
  # NCCL optimization settings
  NCCL_DEBUG: "INFO"
  NCCL_SOCKET_IFNAME: "eth0"
  # Ray settings
  RAY_BACKEND_LOG_LEVEL: "warning"
  PYTHONUNBUFFERED: "1"
---
apiVersion: v1
kind: Service
metadata:
  name: ray-head
  namespace: ray-cluster
spec:
  type: NodePort
  selector:
    app: ray
    component: head
  ports:
  - name: client
    port: 10001
    targetPort: 10001
    nodePort: 30001
  - name: dashboard
    port: 8265
    targetPort: 8265
    nodePort: 30265
  - name: redis
    port: 6379
    targetPort: 6379
    nodePort: 30379
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-head
  namespace: ray-cluster
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ray
      component: head
  template:
    metadata:
      labels:
        app: ray
        component: head
    spec:
      serviceAccountName: ray-serviceaccount
      containers:
      - name: ray-head
        image: ray-training-laptop:latest
        imagePullPolicy: IfNotPresent
        command:
        - /bin/bash
        - -c
        - |
          ray start --head \
            --port=6379 \
            --ray-client-server-port=10001 \
            --dashboard-host=0.0.0.0 \
            --dashboard-port=8265 \
            --include-dashboard=true \
            --num-cpus=4 \
            --num-gpus=1 \
            --object-store-memory=2000000000 \
            --disable-usage-stats \
            --block
        ports:
        - containerPort: 6379
          name: redis
        - containerPort: 8265
          name: dashboard
        - containerPort: 10001
          name: client
        envFrom:
        - configMapRef:
            name: ray-config
        env:
        - name: RAY_MEMORY_MONITOR_REFRESH_MS
          value: "0"
        resources:
          requests:
            cpu: "2"
            memory: "4Gi"
          limits:
            cpu: "4"
            memory: "8Gi"
        volumeMounts:
        - name: shared-data
          mountPath: /mnt/data
        - name: checkpoints
          mountPath: /mnt/checkpoints
        - name: dshm
          mountPath: /dev/shm
      volumes:
      - name: shared-data
        emptyDir: {}
      - name: checkpoints
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 2Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ray-worker
  namespace: ray-cluster
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ray
      component: worker
  template:
    metadata:
      labels:
        app: ray
        component: worker
    spec:
      serviceAccountName: ray-serviceaccount
      containers:
      - name: ray-worker
        image: ray-training-laptop:latest
        imagePullPolicy: IfNotPresent
        command:
        - /bin/bash
        - -c
        - |
          until ray health-check --address=ray-head:6379 2>/dev/null; do
            echo "Waiting for Ray head at ray-head:6379..."
            sleep 2
          done
          echo "Ray head is ready, starting worker..."
          ray start \
            --address=ray-head:6379 \
            --num-cpus=4 \
            --num-gpus=1 \
            --object-store-memory=4000000000 \
            --block
        envFrom:
        - configMapRef:
            name: ray-config
        env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: RAY_MEMORY_MONITOR_REFRESH_MS
          value: "0"
        - name: PYTORCH_CUDA_ALLOC_CONF
          value: "max_split_size_mb:512"
        - name: OMP_NUM_THREADS
          value: "4"
        resources:
          requests:
            cpu: "4"
            memory: "8Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "8"
            memory: "16Gi"
            nvidia.com/gpu: "1"
        volumeMounts:
        - name: shared-data
          mountPath: /mnt/data
        - name: checkpoints
          mountPath: /mnt/checkpoints
        - name: dshm
          mountPath: /dev/shm
      volumes:
      - name: shared-data
        emptyDir: {}
      - name: checkpoints
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 4Gi
      # volumes:
      # - name: shared-data
      #   persistentVolumeClaim:
      #     claimName: ray-data-pvc
      # - name: checkpoints
      #   persistentVolumeClaim:
      #     claimName: ray-checkpoints-pvc
