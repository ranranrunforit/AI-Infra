apiVersion: ml.example.com/v1
kind: TrainingJob
metadata:
  name: gpt2-resume
  namespace: ml-training
spec:
  model: gpt2
  dataset: wikitext
  numWorkers: 8
  gpusPerWorker: 4
  framework: pytorch
  image: nvcr.io/nvidia/pytorch:23.10-py3
  hyperparameters:
    learningRate: 0.0001
    batchSize: 8
    epochs: 20
    optimizer: adamw
  checkpoint:
    enabled: true
    frequency: 2
    resumeFrom: s3://ml-checkpoints/gpt2-training/checkpoint-epoch-10
    storage:
      type: s3
      s3Bucket: ml-checkpoints
    retention: 10
  resources:
    requests:
      memory: 128Gi
      cpu: "32"
      nvidia.com/gpu: "4"
    limits:
      memory: 256Gi
      cpu: "64"
      nvidia.com/gpu: "4"
  scheduling:
    nodeSelector:
      node-type: gpu-large
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: training-job
                    operator: In
                    values:
                      - gpt2-resume
              topologyKey: kubernetes.io/hostname
